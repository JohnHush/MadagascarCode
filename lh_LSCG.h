/* This file is automatically generated. DO NOT EDIT! */

#ifndef _lh_LSCG_h
#define _lh_LSCG_h


void lh_direct_LS( float **G	/* The Forward Operator */,
		   int Nr	/* Row Of G */,
		   int Nc	/* Column of G */,
		   float **Cd	/* The Covariance Matrix of Data Cd[Nr][Nr] */,
		   float **Cm 	/* The Covariance Matrix of model Cm[Nc][Nc] */,
		   float *d	/* Data */,
		   float *m_prior /* m prior */,
		   float *m_post  /* m posterior */ );
/*< Solve the Least Square Optimization Problem directly Using Matrix Inverse >*/


void LSCG_revised( float **a		/* The Matrix A in the left Hand A[NZ][NX] NZ row number NX column number */,
		   float *x		/* The solution vector */,
		   float *b		/* The data vector in the right Hand */,
		   int nz		/* The Row number of A */,
		   int nx		/* The Column Number of A */,
		   float *lamda		/* The Pre-whiting Coefficient */,
		   float eps		/* The tolerance error */,
		   int MaxStep		/* The Maximum Iterative step*/);
/*< LSCG Method To Solve Ax=b >*/


void lh_CG( float **a	/* The Matrix A[N][N] should be positive definite */,
	   float *b	/* THe Right-hand vecotr of the Equation Ax=b */,
	   float *x	/* The Solution */,
	   int n	/* The dimension */,
	   float eps	/* The error torrelence */);
/*< Solve Equation Ax=b, A is positive definite matrix ... Using Conjugate Gradient Method >*/

#endif
